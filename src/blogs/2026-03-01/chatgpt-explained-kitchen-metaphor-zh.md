# 一个厨房学徒是怎么学会做菜的 —— 用一间厨房讲清楚 ChatGPT

*灵感来自 Andrej Karpathy 的 [MicroGPT](https://karpathy.github.io/2026/02/12/microgpt/) —— 200 行代码，证明这一切不过是一间厨房的事。*

---

你第一次走进一家 Omakase 料理店。

服务员引你坐到吧台前。没有菜单。主厨点点头，开始了。

一道道菜依次呈上 —— 先是刺身，然后是热的，然后是带酸的，然后浓郁，然后清淡。每一道菜来得都像是理所当然。等甜品上桌的时候，你突然发现：你从头到尾没有一次想过「这道菜放在这里不对」。整顿饭像是专门为你设计的，出自某个懂你却从未见过你的人。

上周读完 Andrej Karpathy（OpenAI 联合创始人、特斯拉前 AI 负责人）的文章之后，这个问题就一直在我脑子里转：主厨是怎么「知道」的？

不是那位有二十年经验的老师傅。我是说 —— 任何一个厨师，从零开始，是怎么学会给一个素未谋面的陌生人设计出「感觉对」的上菜顺序的？没有人给他一本规则手册。他也没有把所有可能的套餐顺序都背下来。

答案是：小明。

---

认识一下小明：一个学徒厨师，一面墙上的 4,192 个旋钮，和 32,000 份怀石料理记录。（4,192 不是为了好记凑出来的数字 —— 这是 Karpathy 那 200 行代码里真实的参数计数。）

那 32,000 份记录是前辈大师的全部作品集 —— 每一套怀石套餐，每一道菜，按顺序写下来。小明研究了全部。

那 4,192 个旋钮是另一回事。它们在小明的脑子里。每个旋钮编码着他后天习得的一小片判断力：*「第三道菜如果很浓郁，对第四道菜的选择影响有多大？开头几道以海鲜为主，中间是否应该换换口味？一整套下来，口感的变化节奏有多重要？」*

4,192 个微小的直觉。合在一起，构成他全部的厨艺判断。

在这间厨房里，小明是唯一的决策者 —— 所有关于「下一道菜是什么」的判断，最终都由他做出。你在后面会遇到「副厨」和「师傅」，先做个简单介绍：**副厨**协助小明思考，出意见但不做决定；**师傅**是训练阶段专门帮小明调节旋钮的老手，练习结束后就离场了。正式上菜时，只有小明。

他从什么都不懂开始。每个旋钮都设在随机的位置。训练结束时，这些旋钮将会编码出近乎一位大师的品味。

这就是 ChatGPT 的工作原理。不是比喻。是字面意思。

Karpathy 用 200 行代码证明了这一点。今天，我带你走进这间厨房。

---

## 第一章：食材 —— 32,000 套怀石记录

小明有前辈大师的作品集：32,000 套完整的怀石套餐，每道菜按顺序记录在案。

「emma」是一套 4 道菜的套餐：e → m → m → a。「sophia」是 6 道菜：s → o → p → h → i → a。小明只能看到上了什么，以及上菜的顺序。没有食谱，没有解释，只有序列本身。

他的目标：研究足够多的套餐之后，设计出让食客说「感觉对」的新套餐。

有一点值得先说清楚：在这个简化的厨房里，菜单只有 27 道菜，每道菜用一个字母代号标注。「e」不是「鳗鱼寿司」—— 它只是 27 道菜里第 5 道菜的代号。这些代号本身没有任何具体含义，重要的只是*顺序*：哪个代号跟在哪个后面，以及在数万套套餐里涌现出什么样的规律。

**为什么顺序那么重要？** 因为同样四道菜 —— 「刺身→烤物→汤→甜品」和「甜品→汤→烤物→刺身」，是完全不同的用餐体验。「emma」和「amme」包含相同的食材，却是完全不同的体验。就像「狗咬人」和「人咬狗」，同样四个字，意思天壤之别。

**放大到 ChatGPT：** 它的作品集不是 32,000 个名字，而是整个互联网 —— 所有写过的书、文章、对话、帖子。万亿套「怀石记录」，全部按顺序消化。

关键感受：小明没有背下每一套套餐的序列。他形成了*直觉* —— 对「什么应该跟在什么后面」的感知，对「这个组合感觉对」的判断。没有规则手册，只有模式，反复吸收，直到变成本能。

> *小明不是在记忆，他在培养品味。*

---

## 第二章：拆解 —— 一道菜一道菜地学

一整套怀石太复杂，没法整套学。第一步是把它拆成一道道单独的菜。

「emma」变成：[🛎️, e, m, m, a, 🛎️]

那个服务铃 🛎️ 标记着每套套餐的开始和结束。每道单独的菜是一个 **token** —— 厨房处理的最小意义单位。

但小明的厨房不认识菜名，它只认识数字。所以每道菜都要编号：

a = 0，b = 1，c = 2……z = 25，🛎️ = 26

「emma」变成：[26, 4, 12, 12, 0, 26]

光有数字还不够。数字只是一个标签 —— 它告诉你*是哪道*菜，却什么都没说明这道菜的*性格*。所以每个编号还附带一张**风味档案卡**：16 个数字，描述这道菜的属性，比如浓郁度、温度、口感、酸度。这些档案一开始完全随机，在训练中逐渐变得有意义。

ChatGPT 的编号系统更聪明 —— 常见的词语组合会拿到一个单独的编号，不用一个字母一个字母地拼。比如「hello」在 ChatGPT 的词汇表里是一道独立的菜，不需要拆成 h、e、l、l、o 五道分开处理。更高效，更有表达力。词汇量大约 10 万个「菜品」，而不是 27 个。

> *你打出的每一个字都变成数字，每个数字都携带一张风味档案。这就是机器开始「读懂」语言的方式。*

---

## 第三章：出菜流水线 —— 下一道应该是什么？

这是一切汇聚的地方。小明在每个时刻只需要回答一个问题：**下一道菜应该是什么？**

假设「emma」这套套餐已经上了前三道菜（e, m, m），现在第四道「m」刚刚到达厨房。小明的任务：决定第五道是什么。

这道菜从厨房入口出发，经过三个关键站点，另一端出来的是答案：

```
第四道菜「m」到达
        ↓
[1] 回头看 —— 副厨圆桌  ← 唯一回头的地方
        ↓
[2] 想清楚 —— 后厨加工
        ↓
[3] 下注 —— 最终投票
        ↓
27 道菜的概率排名
```

整件事分三步。每一步之间，有两个幕后动作悄悄发生。我们先把三步说清楚，再说那两个配角。

---

### 第一步：回头看 —— 副厨圆桌

这是整条流水线上**唯一一个会看之前菜品的地方**。

第四道菜「m」被放到桌子中央。四位副厨围坐在四周，每人负责追踪这顿饭到目前为止的一个不同维度：

- 副厨甲追踪浓郁度，翻开笔记本：「第一道清淡，第二道浓郁，第三道浓郁……」
- 副厨乙追踪口感：「连续三道都是软的 —— 该来点有嚼劲的了？」
- 副厨丙追踪温度，副厨丁追踪酸碱感。

每位副厨提一个问题：*「按我追踪的维度，前面哪道菜对现在的决定最有参考价值？」* 之前三道菜逐一回应：*「这是我的情况。」* 匹配度高的，把详细信息传递过来；匹配度低的，直接跳过。

四位副厨把各自的发现汇总，传向下一站。

有一点值得一提：副厨不需要重新品尝之前的菜。从第一道菜开始，他们就把每道菜的信息记在了笔记本里。每道新菜只需要新增一页 —— 这是这间厨房的记忆方式，记过的不用重来。

> *副厨圆桌做的事只有一件：告诉小明，过去发生的哪些事，和下一道菜的决定最有关。*

---

### 第二步：想清楚 —— 后厨加工

副厨圆桌问完了该问的。现在，小明要自己想清楚。

后厨有一个工作习惯：先把问题完全打开 —— 在一个宽阔得多的空间里，同时考虑所有可能的方向。然后，品控把显然行不通的方向全部划掉（凡是出现负面信号的，直接清零）。最后，把结论收拢回来，提炼成清晰的判断。

打开，筛选，收拢。结果是一份精炼的「对第五道菜该是什么的理解」。

> *副厨圆桌是向外看：历史告诉我什么？后厨是向内看：我自己怎么判断？*

---

### 第三步：下注 —— 最终投票

后厨加工完成。小明对所有 27 道可能的下一道菜分别打分：

*「第五道是 'a' 的可能性 70%，是 'e' 的可能性 15%，是 'i' 的可能性 8%……」*

原始分数转换成百分比，加起来等于 100%。这不是一个确定的答案 —— 是一个有把握的押注。

> *小明不知道答案，他在下注。全部魔法，在于他怎样越押越准。*

---

### 幕后的两个配角

整个流程里还有两个动作，不是主角，但少了它们厨房会出问题。

**漱口（每个主站点之前）：** 每次进入副厨圆桌或后厨之前，先漱口、重置味觉。这保证每次判断的起点是一致的 —— 刚吃完特别辣的东西马上品精细料理，感知会失真。漱口让每一次判断都从同一个基准出发。

**混入一勺原味（每个主站点之后）：** 副厨圆桌结束后、后厨加工结束后，各有一个动作：把这道菜最初的原始档案混回去一勺。就像做酱汁浓缩时，永远在旁边留一锅原汤，每次收汁后加回来一点 —— 防止菜品经过一次次加工后，把自己原本的样子完全丢失。

在小明的厨房（MicroGPT）里，这三步走一遍就结束了。ChatGPT 的厨房把同样的三步叠加了几十次：第一轮的输出，是第二轮的输入，同样的副厨和后厨，每一轮理解得更深一层。

---

## 第四章：食客的打分 —— 你做得有多差？

小明设计了一套怀石套餐。每道菜上桌，都有一个评分机制：**小明对正确答案给了多大的把握？**

假设下一道菜实际上是「a」：

- 小明给「a」押了 100% 的把握 —— 零惩罚，满分
- 小明给「a」只押了 10% —— 大惩罚
- 小明给「a」只押了 0.1% —— 巨大惩罚

这个惩罚就是**损失值（Loss）**。损失越低，厨艺越好。

起始损失：3.3。这是在 27 个选项里纯随机猜测的水平。一个完全的厨房新手，闭着眼睛随机摆盘。

整个训练过程只有一个使命：**把这个数字降下去。**

> *小明的每一个决定都可以用一个数字来评判。这个数字是北极星。*

---

## 第五章：追根溯源 —— 是谁让菜变咸了？

这是整件事的核心 —— 也是让整个系统真正变得聪明的地方。

分数出来了：「太差。」小明面对那面墙上的 4,192 个旋钮，不知道从哪儿下手。一个一个试？要几年。

但他可以做一件更聪明的事：**从盘子开始往回追。**

食客吃了一口：「太咸了。」

### 从盘子追到厨房

「这口太咸了 → 最后一步是摆盘（没加盐）→ 再往前是后厨加工（加了酱油）→ 再往前是副厨圆桌（参考了第二道菜的档案）→ 追回到旋钮 #347（酱油浓度调节）。」

这就是**反向传播（Backpropagation）** —— 从结果出发，沿着因果链条往回追到源头。

### 接力传递（链式法则 Chain Rule）

每个检查站只需要知道一件简单的事：*「如果我的输入变化了一点点，我的输出会变化多少？」*

- 把旋钮 #347 调大 1 → 汤底咸度增加 3
- 汤底咸度增加 1 → 最终口味变化 2
- 旋钮 #347 对最终口味的总影响 = 3 × 2 = **6**

沿着流水线走，在每一步相乘。这就是链式法则 —— 不需要微积分，只需要沿路相乘。

### 六种基本烹饪手法

整间厨房只用六种烹饪操作。每一个检查站、每一处计算，最终都归结为这六种之一。更关键的是：每种手法都能精确地追溯自身 —— 这正是「从盘子往回追」能一路追到每个旋钮的原因。

| 手法 | 在厨房里做什么 |
|------|--------------|
| **合并**（加法） | 把两样东西倒在一起 |
| **融合**（乘法） | 两种食材相互放大 |
| **浓缩**（幂次） | 把风味集中 |
| **提取**（对数） | 一点点就够用 |
| **发酵**（指数） | 指数级增长 |
| **品控**（ReLU） | 好的通过，差的扔掉 |

ChatGPT 的整间厨房只用这六种手法。没有第七种。

### 一个具体的例子

小明做一道简单的两步菜：
- 材料：2 份盐，3 份糖
- 第一步：**融合** → 咸甜底味 = 6
- 第二步：**合并** → 最终口味 = 底味 + 额外一撮盐 = 8

食客说味道不对。往回追：
- 最终口味 = 底味 + 盐 → 合并 → 底味的影响 = 1，盐的影响 = 1
- 底味 = 盐 × 糖 → 融合 → 盐在这里的影响 = 糖的量 = 3

盐出现了两次（融合里一次，合并里一次），总影响 = 3 + 1 = **4**。糖只出现一次：影响 = 2。

现在小明知道了：盐对结果的影响是糖的两倍。这就是**梯度（Gradient）= 4** 的意思。调盐要小心，调糖可以大胆一点。

> *小明不是在猜该转哪个旋钮，他在精确计算每个旋钮有多重要。*

---

## 第六章：师傅的训练方法 —— 一千道菜

小明开始苦练。每道菜，同样三个步骤：

1. **出菜（前向传播）** —— 用当前旋钮位置，把当前菜品过一遍流水线
2. **追溯（反向传播）** —— 食客打分后，从盘子开始往回追，找出每个旋钮的影响数值
3. **调整（参数更新）** —— 根据每个旋钮的影响数值，往「减少惩罚」的方向拨一点

前两步有明确的规则可循。第三步才是真正的难题：4,192 个旋钮，该怎么调？每个都拨一样的幅度吗？哪些要轻，哪些要重？激进地大幅调整，还是保守地小步试探？

这件事，小明一个人搞不定。所以训练时，旁边站着一位专门负责调节的老手，他叫师傅。

### 调节大师 师傅

不是每个旋钮都接受同样幅度的调整。师傅比「一刀切」聪明得多。

**记忆（动量 Momentum）：** 师傅记得最近几轮的调整方向。如果过去五轮都说「把旋钮 #347 调小」，第六轮就更大胆地调。就像一个球滚下坡 —— 它积累势头，而不是来回弹跳。

**因材施教（自适应学习率）：** 有些旋钮极度敏感 —— 轻轻一拨就引发巨大变化。师傅对这些旋钮轻手轻脚。有些旋钮很迟钝 —— 大力拨动才有小小变化。师傅使劲拧。

**越来越轻（学习率衰减）：** 训练初期调整大胆 —— 你离好还很远，激进一点没关系。越接近优秀，调整越精细。越接近完美，越需要如履薄冰。

### 成长曲线

| 第几道菜 | 损失值 | 厨房里发生了什么 |
|---------|--------|----------------|
| 第 1 道 | 3.3 | 蒙眼摆盘 —— 刺身后面上甜品，全程油炸，一片混乱 |
| 第 100 道 | ~2.8 | 学会了「怀石一般先清淡，收尾浓郁」 |
| 第 500 道 | ~2.5 | 学会了「味噌和白饭总是成对出现」「不能连上三道油炸」 |
| 第 1000 道 | 2.37 | 设计出食客真正信任的套餐 |

**小明从未记住过一条规则。** 没有人告诉他「不能连上三道油炸」，也没有人解释「味噌配白饭」。他只是一遍遍地出菜→追溯→调整，直到旋钮自然地稳定在那些反映这些规律的位置上。

这就是「习得直觉」的意思。无师自通，不是因为天才，而是因为重复。

> *智慧不是从规则里来的，是从重复里来的。*

---

## 第七章：出师 —— 小明独自掌厨

训练结束。旋钮锁定在最终位置。不再是练习 —— 真实的食客已经就坐。

1. 服务铃响起 🛎️ —— 「开始一套新的怀石」
2. 小明根据当前旋钮位置设计第一道菜
3. 第一道菜过一遍流水线，从中推导出第二道应该是什么
4. 第二道推导出第三道，第三道推导出第四道
5. 一直到小明自然地产出收尾铃声 🛎️

每一道菜都是即兴的 —— 没有预先写好的菜单 —— 但都建立在之前所有菜的基础上。就像真正的怀石主厨在读桌 —— 第一道菜塑造了第二道，整顿饭的氛围决定了结尾。

### 冒险旋钮（温度 Temperature）

厨房门口有一个旋钮，它不影响厨艺水平，只影响*风格*。

- **Temperature = 0.1**（极度保守）→ 永远选最安全的选项 → 稳，但无聊
- **Temperature = 0.5**（略有冒险）→ 基本连贯，偶有惊喜
- **Temperature = 1.5**（大胆冒进）→ 可能惊艳，也可能一塌糊涂

ChatGPT 大约在 0.7。有一点创意，但不会失控。

### 关于「发明菜品」（幻觉 Hallucination）

训练结束后，小明生成了「Karia」、「Yeran」、「Liole」—— 这些是 Karpathy 的模型实际输出的名字，听起来像真实的人名，感觉合理，好像某个地方确实有人叫这个名字。但大多数可能根本不存在于任何训练数据中。

他没有在撒谎。他只是在沿着习得的规律延伸 —— 在统计上看起来合理的组合。他满怀把握地呈上来，但它们从未真实存在过。

当 ChatGPT 自信地引用一篇不存在的论文，或者说出一个不存在的日期时，它做的事和小明发明「karia」完全一样。它没有事实核查站，只知道什么「味道对」，不知道什么「是真实的」。

> *小明可以用一种从未被收获过的食材，设计出一套无懈可击的怀石套餐。这是这间厨房的工作方式决定的代价。*

---

## 第八章：从街边小摊到米其林三星

小明用 4,192 个判断旋钮和 32,000 套训练记录学会了做菜。ChatGPT 呢？

| | 小明（街边怀石） | ChatGPT（米其林三星） |
|--|---|---|
| 判断旋钮 | 4,192 个 | 数千亿个 |
| 训练记录 | 32,000 套名字序列 | 万亿套序列（整个互联网） |
| 菜品词汇 | 27 个字母 + 一个铃 | 约 10 万个词块 |
| 厨房 | 一口灶（MacBook） | 数千口灶并行运转（GPU 集群） |
| 训练时长 | 1 分钟 | 数个月 |
| **烹饪原理** | **完全相同** | **完全相同** |

同一间厨房，天壤之别的规模。

### 三星厨房的额外步骤

ChatGPT 没有止步于基础训练。两个额外阶段让它从技术上正确变成真正好用。

**第一阶段 —— 换菜单（有监督微调 SFT）：** 小明先在简单的名字序列上训练，建立起基础的「顺序感」。然后换成多轮对话 —— 复杂的来回交流 —— 继续训练。同样的出菜→追溯→调整算法，不同的训练材料。就像厨师先把鸡蛋做到炉火纯青，再去研习法餐。基本功不变，曲目扩展。

**第二阶段 —— 请来食评家（基于人类反馈的强化学习 RLHF）：** 小明做两道菜，食评家选出更好的那道。根据食评家的偏好调整旋钮，反复数百万次。

这就是为什么 ChatGPT「有礼貌」、「乐于助人」—— 不是因为有人写了一条规则说「要有礼貌」。而是因为人类食评家，在数百万次比较中，持续选择了那些感觉有帮助、有分寸的回应。那些偏好被烤进了旋钮里。

贯穿始终，核心从未改变：**出菜 → 打分 → 追溯 → 调整。**

> *从 200 行代码到数千亿参数：同样的六种手法，同样的三个步骤。只是更多旋钮，更多菜品，更多食客。*

---

## 这间厨房，说白了

下次有人告诉你 AI 很神秘、很可怕、或者即将取代人类 —— 想起那个坐在吧台前的食客。

没有菜单，菜品一道道端上来，一切都显得理所当然。

这背后：一个学徒，一面墙的判断旋钮，32,000 套记录。没人给他规则，只有出菜→打分→追溯→调整。做足够多次，旋钮自然稳定下来。

这不是智慧，是被打磨得足够精细、以至于与品味无法区分的统计直觉。

但这么简单的机制 —— 六种操作，三个步骤，一个循环 —— 居然能产出一个可以聊天、解释概念、写文章、让你感觉到「有人在」的东西？

*这才*是真正令人叹为观止的地方。

200 行代码。六种手法。一间厨房。

这就是 ChatGPT 的全部。

---

*想看那实际的 200 行，Andrej Karpathy 的 [MicroGPT](https://karpathy.github.io/2026/02/12/microgpt/) 值得一读。他建了这间厨房，我只是给它起了个名字，带你转了一圈。*

---

## 比喻对照表

| GPT 概念 | 厨房比喻 |
|---------|---------|
| 模型（Model） | 小明，学徒厨师 |
| 参数（Parameters） | 4,192 个判断旋钮 —— 编码小明习得的顺序直觉 |
| 训练数据（Dataset） | 前辈大师的 32,000 套怀石记录（不是食谱，只有顺序） |
| Token（词元） | 怀石套餐里的一道菜 |
| 分词器（Tokenizer） | 把一整套套餐拆解成一道道单菜的系统 |
| BOS / EOS Token | 服务铃 🛎️ —— 「新套餐开始」/「套餐结束」 |
| 词向量（Embedding） | 风味档案卡 —— 16 个数字编码一道菜的性格 |
| 位置编码（Position Embedding） | 序列标签 —— 「这是第 3 道菜」 |
| 注意力机制（Attention） | 副厨查阅笔记本，参考之前的菜品 |
| Query / Key / Value | Q = 「我现在需要什么？」K = 「我之前提供过这个」V = 「如果你选我，这是我的食谱」 |
| 多头注意力（Multi-head Attention） | 4 位副厨同时查阅，各自追踪不同维度 |
| KV Cache | 笔记本 —— 不需要重新品尝已经记录过的内容 |
| MLP（前馈网络） | 后厨 —— 向同事请教之后，独立思考 |
| ReLU | 品控 —— 差的清零，好的通过 |
| 残差连接（Residual Connection） | 每一步之后混回去的那一勺原汤 |
| RMSNorm | 每个检查站之前的漱口 |
| 损失（Loss） | 食客的惩罚分 —— 离完美有多远？ |
| Softmax | 把原始评分转换成概率排名 |
| 反向传播（Backpropagation） | 沿着流水线往回追「太咸」追到旋钮 #347 |
| 梯度（Gradient） | 每个旋钮的影响系数 —— 它对最终结果的推动力有多大？ |
| 链式法则（Chain Rule） | 沿着流水线逐步相乘 |
| Adam 优化器 | 师傅 —— 有记忆、因材施教、越来越轻手的调节大师 |
| 温度（Temperature） | 冒险旋钮 —— 低 = 保守，高 = 创意 |
| 幻觉（Hallucination） | 发明「karia」—— 统计上合理，从未真实存在 |
| MicroGPT → ChatGPT | 街边小摊 → 米其林三星 —— 同样的原理，天壤之别的规模 |
